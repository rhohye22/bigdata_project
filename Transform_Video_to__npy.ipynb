{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Transform_Video_to _npy.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "mount_file_id": "1KxWhh3T1jqqa6Fq-y-4L4f29LRGh_FgO",
      "authorship_tag": "ABX9TyM2JbTUD2s2f6l5uoImdDnj",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rhohye22/bigdata_project/blob/main/Transform_Video_to__npy.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FU1G6QL6wYDR"
      },
      "source": [
        "import cv2  \n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import os \n",
        "from tqdm import tqdm"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fscpavXywy-i"
      },
      "source": [
        "# Transform Video to .npy Format"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OkAz5Kqxw1ba"
      },
      "source": [
        "\n",
        "def getOpticalFlow(video):\n",
        "    \"\"\"Calculate dense optical flow of input video\n",
        "    Args:\n",
        "        video: the input video with shape of [frames,height,width,channel]. dtype=np.array\n",
        "    Returns:\n",
        "        flows_x: the optical flow at x-axis, with the shape of [frames,height,width,channel]\n",
        "        flows_y: the optical flow at y-axis, with the shape of [frames,height,width,channel]\n",
        "    \"\"\"\n",
        "    # initialize the list of optical flows\n",
        "    gray_video = []\n",
        "    for i in range(len(video)):\n",
        "        img = cv2.cvtColor(video[i], cv2.COLOR_RGB2GRAY)\n",
        "        gray_video.append(np.reshape(img,(224,224,1)))\n",
        "\n",
        "    flows = []\n",
        "    for i in range(0,len(video)-1):\n",
        "        # calculate optical flow between each pair of frames\n",
        "        flow = cv2.calcOpticalFlowFarneback(gray_video[i], gray_video[i+1], None, 0.5, 3, 15, 3, 5, 1.2, cv2.OPTFLOW_FARNEBACK_GAUSSIAN)\n",
        "        # subtract the mean in order to eliminate the movement of camera\n",
        "        flow[..., 0] -= np.mean(flow[..., 0])\n",
        "        flow[..., 1] -= np.mean(flow[..., 1])\n",
        "        # normalize each component in optical flow\n",
        "        flow[..., 0] = cv2.normalize(flow[..., 0],None,0,255,cv2.NORM_MINMAX)\n",
        "        flow[..., 1] = cv2.normalize(flow[..., 1],None,0,255,cv2.NORM_MINMAX)\n",
        "        # Add into list \n",
        "        flows.append(flow)\n",
        "        \n",
        "    # Padding the last frame as empty array\n",
        "    flows.append(np.zeros((224,224,2)))\n",
        "      \n",
        "    return np.array(flows, dtype=np.float32)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6DTGPB3Byhfb"
      },
      "source": [
        "## 영상 > npy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9JERpT7pw_lq"
      },
      "source": [
        "def Video2Npy(file_path, resize=(224,224)):\n",
        "    \"\"\"Load video and tansfer it into .npy format\n",
        "    Args:\n",
        "        file_path: the path of video file\n",
        "        resize: the target resolution of output video\n",
        "    Returns:\n",
        "        frames: gray-scale video\n",
        "        flows: magnitude video of optical flows \n",
        "    \"\"\"\n",
        "    # Load video\n",
        "    cap = cv2.VideoCapture(file_path)\n",
        "    # Get number of frames\n",
        "    len_frames = int(cap.get(7))\n",
        "    # Extract frames from video\n",
        "    try:\n",
        "        frames = []\n",
        "        for i in range(len_frames-1):\n",
        "            _, frame = cap.read()\n",
        "            frame = cv2.resize(frame,resize, interpolation=cv2.INTER_AREA)\n",
        "            frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
        "            frame = np.reshape(frame, (224,224,3))\n",
        "            frames.append(frame)   \n",
        "    except:\n",
        "        print(\"Error: \", file_path, len_frames,i)\n",
        "    finally:\n",
        "        frames = np.array(frames)\n",
        "        cap.release()\n",
        "            \n",
        "    # Get the optical flow of video\n",
        "    flows = getOpticalFlow(frames)\n",
        "    \n",
        "    result = np.zeros((len(flows),224,224,5))\n",
        "    result[...,:3] = frames\n",
        "    result[...,3:] = flows\n",
        "    \n",
        "    return result"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m-xTNicVyp9D"
      },
      "source": [
        "## npy 저장"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7QfyUvtE67n0",
        "outputId": "7dc137dc-2be1-468a-9b40-db6fbdf7784c"
      },
      "source": [
        "Save2Npy('/content/drive/MyDrive/4_19data/example', '/content/drive/MyDrive/4_19data/example_npy')"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 3/3 [00:04<00:00,  1.59s/it]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C37WgJlQxAfS"
      },
      "source": [
        "def Save2Npy(file_dir, save_dir):\n",
        "    \"\"\"Transfer all the videos and save them into specified directory\n",
        "    Args:\n",
        "        file_dir: source folder of target videos\n",
        "        save_dir: destination folder of output .npy files\n",
        "    \"\"\"\n",
        "    if not os.path.exists(save_dir):\n",
        "        os.makedirs(save_dir)\n",
        "    # List the files\n",
        "    videos = os.listdir(file_dir)\n",
        "    for v in tqdm(videos):\n",
        "        # Split video name\n",
        "        video_name = v.split('.')[0]\n",
        "        # Get src \n",
        "        video_path = os.path.join(file_dir, v)\n",
        "        # Get dest \n",
        "        save_path = os.path.join(save_dir, video_name+'.npy') \n",
        "        # Load and preprocess video\n",
        "        data = Video2Npy(file_path=video_path, resize=(224,224))\n",
        "        data = np.uint8(data)\n",
        "        # Save as .npy file\n",
        "        np.save(save_path, data)\n",
        "    \n",
        "    return None"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zFg-hMlS62Z0"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_jhfbWmGxIP7"
      },
      "source": [
        "\n",
        "# TODO Here¶\n",
        "  * replace the source_path to the path of original dataset\n",
        "  * replace the target_path to where you want to save transformed data\n",
        "\n",
        "  * 원본 데이터 세트의 경로로 source_path 교체\n",
        "  * 변환된 데이터를 저장할  target_path를 교체"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NsljHTMdxMqL",
        "outputId": "58ea2fb7-4f9c-40a5-b456-d15be0886bbe"
      },
      "source": [
        "source_path = '/content/drive/MyDrive/violence data/RWF-2000 Dataset'\n",
        "target_path = '/content/drive/MyDrive/4_19data'\n",
        "\n",
        "for f1 in ['train','val']:\n",
        "    for f2 in ['Fight', 'NonFight']:\n",
        "        path1 = os.path.join(source_path, f1, f2)\n",
        "        path2 = os.path.join(target_path, f1, f2)\n",
        "        Save2Npy(file_dir=path1, save_dir=path2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 200/200 [18:20<00:00,  5.50s/it]\n",
            "100%|██████████| 200/200 [17:09<00:00,  5.15s/it]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IFonot5icZgS",
        "outputId": "34f18f83-3b50-44a0-af07-6f5f2e0402cf"
      },
      "source": [
        "source_path = '/content/drive/MyDrive/violence data/RWF-2000 Dataset'\n",
        "target_path = '/content/drive/MyDrive/4_19data'\n",
        "\n",
        "for f1 in ['train','val']:\n",
        "    for f2 in ['Fight', 'NonFight']:\n",
        "        path1 = os.path.join(source_path, f1, f2)\n",
        "        path2 = os.path.join(target_path, f1, f2)\n",
        "        Save2Npy(file_dir=path1, save_dir=path2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 800/800 [1:04:28<00:00,  4.84s/it]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NvjmSIbccFtl",
        "outputId": "bb097e57-6e90-4380-f050-b0438deb78d9"
      },
      "source": [
        "len(os.listdir('/content/drive/MyDrive/4_19data/val/Fight'))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "200"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    }
  ]
}