{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "pretrain_model.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "mount_file_id": "19OD_Ljq5LdCBnKW79UkzOOlthsmq9Kvo",
      "authorship_tag": "ABX9TyO7xlOVVxOqDjkp5I9pcyjO",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rhohye22/bigdata_project/blob/main/pretrain_model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vBYoXuGzDjR1"
      },
      "source": [
        "## Build Data Loader\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sy4EMGZ9DCN3"
      },
      "source": [
        "from keras.utils import Sequence\n",
        "from keras.utils import np_utils\n",
        "\n",
        "class DataGenerator(Sequence):\n",
        "    \"\"\"Data Generator inherited from keras.utils.Sequence\n",
        "    Args: \n",
        "        directory: the path of data set, and each sub-folder will be assigned to one class\n",
        "        batch_size: the number of data points in each batch\n",
        "        shuffle: whether to shuffle the data per epoch\n",
        "    Note:\n",
        "        If you want to load file with other data format, please fix the method of \"load_data\" as you want\n",
        "    \"\"\"\n",
        "    def __init__(self, directory, batch_size=1, shuffle=True, data_augmentation=True):\n",
        "        # Initialize the params\n",
        "        self.batch_size = batch_size\n",
        "        self.directory = directory\n",
        "        self.shuffle = shuffle\n",
        "        self.data_aug = data_augmentation\n",
        "        # Load all the save_path of files, and create a dictionary that save the pair of \"data:label\"\n",
        "        self.X_path, self.Y_dict = self.search_data() \n",
        "        # Print basic statistics information\n",
        "        self.print_stats()\n",
        "        return None\n",
        "        \n",
        "    def search_data(self):\n",
        "        X_path = []\n",
        "        Y_dict = {}\n",
        "        # list all kinds of sub-folders\n",
        "        self.dirs = sorted(os.listdir(self.directory))\n",
        "        one_hots = np_utils.to_categorical(range(len(self.dirs)))\n",
        "        for i,folder in enumerate(self.dirs):\n",
        "            folder_path = os.path.join(self.directory,folder)\n",
        "            for file in os.listdir(folder_path):\n",
        "                file_path = os.path.join(folder_path,file)\n",
        "                # append the each file path, and keep its label  \n",
        "                X_path.append(file_path)\n",
        "                Y_dict[file_path] = one_hots[i]\n",
        "        return X_path, Y_dict\n",
        "    \n",
        "    def print_stats(self):\n",
        "        # calculate basic information\n",
        "        self.n_files = len(self.X_path)\n",
        "        self.n_classes = len(self.dirs)\n",
        "        self.indexes = np.arange(len(self.X_path))\n",
        "        np.random.shuffle(self.indexes)\n",
        "        # Output states\n",
        "        print(\"Found {} files belonging to {} classes.\".format(self.n_files,self.n_classes))\n",
        "        for i,label in enumerate(self.dirs):\n",
        "            print('%10s : '%(label),i)\n",
        "        return None\n",
        "    \n",
        "    def __len__(self):\n",
        "        # calculate the iterations of each epoch\n",
        "        steps_per_epoch = np.ceil(len(self.X_path) / float(self.batch_size))\n",
        "        return int(steps_per_epoch)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        \"\"\"Get the data of each batch\n",
        "        \"\"\"\n",
        "        # get the indexs of each batch\n",
        "        batch_indexs = self.indexes[index*self.batch_size:(index+1)*self.batch_size]\n",
        "        # using batch_indexs to get path of current batch\n",
        "        batch_path = [self.X_path[k] for k in batch_indexs]\n",
        "        # get batch data\n",
        "        batch_x, batch_y = self.data_generation(batch_path)\n",
        "        return batch_x, batch_y\n",
        "\n",
        "    def on_epoch_end(self):\n",
        "        # shuffle the data at each end of epoch\n",
        "        if self.shuffle == True:\n",
        "            np.random.shuffle(self.indexes)\n",
        "\n",
        "    def data_generation(self, batch_path):\n",
        "        # load data into memory, you can change the np.load to any method you want\n",
        "        batch_x = [self.load_data(x) for x in batch_path]\n",
        "        batch_y = [self.Y_dict[x] for x in batch_path]\n",
        "        # transfer the data format and take one-hot coding for labels\n",
        "        batch_x = np.array(batch_x)\n",
        "        batch_y = np.array(batch_y)\n",
        "        return batch_x, batch_y\n",
        "      \n",
        "    def normalize(self, data):\n",
        "        mean = np.mean(data)\n",
        "        std = np.std(data)\n",
        "        return (data-mean) / std\n",
        "    \n",
        "    def random_flip(self, video, prob):\n",
        "        s = np.random.rand()\n",
        "        if s < prob:\n",
        "            video = np.flip(m=video, axis=2)\n",
        "        return video    \n",
        "    \n",
        "    def uniform_sampling(self, video, target_frames=64):\n",
        "        # get total frames of input video and calculate sampling interval \n",
        "        len_frames = int(len(video))\n",
        "        interval = int(np.ceil(len_frames/target_frames))\n",
        "        # init empty list for sampled video and \n",
        "        sampled_video = []\n",
        "        for i in range(0,len_frames,interval):\n",
        "            sampled_video.append(video[i])     \n",
        "        # calculate numer of padded frames and fix it \n",
        "        num_pad = target_frames - len(sampled_video)\n",
        "        padding = []\n",
        "        if num_pad>0:\n",
        "            for i in range(-num_pad,0):\n",
        "                try: \n",
        "                    padding.append(video[i])\n",
        "                except:\n",
        "                    padding.append(video[0])\n",
        "            sampled_video += padding     \n",
        "        # get sampled video\n",
        "        return np.array(sampled_video, dtype=np.float32)\n",
        "    \n",
        "    def random_clip(self, video, target_frames=64):\n",
        "        start_point = np.random.randint(len(video)-target_frames)\n",
        "        return video[start_point:start_point+target_frames]\n",
        "    \n",
        "    def dynamic_crop(self, video):\n",
        "        # extract layer of optical flow from video\n",
        "        opt_flows = video[...,3]\n",
        "        # sum of optical flow magnitude of individual frame\n",
        "        magnitude = np.sum(opt_flows, axis=0)\n",
        "        # filter slight noise by threshold \n",
        "        thresh = np.mean(magnitude)\n",
        "        magnitude[magnitude<thresh] = 0\n",
        "        # calculate center of gravity of magnitude map and adding 0.001 to avoid empty value\n",
        "        x_pdf = np.sum(magnitude, axis=1) + 0.001\n",
        "        y_pdf = np.sum(magnitude, axis=0) + 0.001\n",
        "        # normalize PDF of x and y so that the sum of probs = 1\n",
        "        x_pdf /= np.sum(x_pdf)\n",
        "        y_pdf /= np.sum(y_pdf)\n",
        "        # randomly choose some candidates for x and y \n",
        "        x_points = np.random.choice(a=np.arange(224), size=10, replace=True, p=x_pdf)\n",
        "        y_points = np.random.choice(a=np.arange(224), size=10, replace=True, p=y_pdf)\n",
        "        # get the mean of x and y coordinates for better robustness\n",
        "        x = int(np.mean(x_points))\n",
        "        y = int(np.mean(y_points))\n",
        "        # avoid to beyond boundaries of array\n",
        "        x = max(56,min(x,167))\n",
        "        y = max(56,min(y,167))\n",
        "        # get cropped video \n",
        "        return video[:,x-56:x+56,y-56:y+56,:]  \n",
        "    \n",
        "    def color_jitter(self,video):\n",
        "        # range of s-component: 0-1\n",
        "        # range of v component: 0-255\n",
        "        s_jitter = np.random.uniform(-0.2,0.2)\n",
        "        v_jitter = np.random.uniform(-30,30)\n",
        "        for i in range(len(video)):\n",
        "            hsv = cv2.cvtColor(video[i], cv2.COLOR_RGB2HSV)\n",
        "            s = hsv[...,1] + s_jitter\n",
        "            v = hsv[...,2] + v_jitter\n",
        "            s[s<0] = 0\n",
        "            s[s>1] = 1\n",
        "            v[v<0] = 0\n",
        "            v[v>255] = 255\n",
        "            hsv[...,1] = s\n",
        "            hsv[...,2] = v\n",
        "            video[i] = cv2.cvtColor(hsv, cv2.COLOR_HSV2RGB)\n",
        "        return video\n",
        "        \n",
        "    def load_data(self, path):\n",
        "        # load the processed .npy files which have 5 channels (1-3 for RGB, 4-5 for optical flows)\n",
        "        data = np.load(path, mmap_mode='r')\n",
        "        data = np.float32(data)\n",
        "        # sampling 64 frames uniformly from the entire video\n",
        "        data = self.uniform_sampling(video=data, target_frames=64)\n",
        "        # whether to utilize the data augmentation\n",
        "        if  self.data_aug:\n",
        "            data[...,:3] = self.color_jitter(data[...,:3])\n",
        "            data = self.random_flip(data, prob=0.5)\n",
        "        # normalize rgb images and optical flows, respectively\n",
        "        data[...,:3] = self.normalize(data[...,:3])\n",
        "        data[...,3:] = self.normalize(data[...,3:])\n",
        "        return data\n"
      ],
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PD9zlifLLbvV"
      },
      "source": [
        "num_epochs  = 30\n",
        "num_workers = 16\n",
        "batch_size  = 8"
      ],
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QITw4A3Ht6Cz"
      },
      "source": [
        "## init data generator"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z7O1iuZ4CQH5",
        "outputId": "ae73c2b9-b947-4a4a-a37b-865355de54bf"
      },
      "source": [
        "import os\n",
        "import numpy as np\n",
        "\n",
        "dataset = 'ViolentFlow-opt'\n",
        "\n",
        "train_generator = DataGenerator(directory='/content/drive/MyDrive/4_19data/train'.format(dataset), \n",
        "                                batch_size=batch_size, \n",
        "                                data_augmentation=True)\n",
        "\n",
        "val_generator = DataGenerator(directory='/content/drive/MyDrive/4_19data/val'.format(dataset),\n",
        "                              batch_size=batch_size, \n",
        "                              data_augmentation=False)"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 1600 files belonging to 2 classes.\n",
            "     Fight :  0\n",
            "  NonFight :  1\n",
            "Found 400 files belonging to 2 classes.\n",
            "     Fight :  0\n",
            "  NonFight :  1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8GuMMznyDqMP"
      },
      "source": [
        "## load model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0tc8nNjz3w51"
      },
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras"
      ],
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EXgqZszbJ3Nt"
      },
      "source": [
        "from keras.models import load_model\n",
        "from keras.optimizers import SGD\n",
        "\n",
        "sgd = SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n",
        "\n",
        "model = load_model('/content/drive/MyDrive/4_19data/keras_model.h5',\n",
        "                  compile=False)\n",
        "model.compile(optimizer=sgd,\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ug7FgDohVoQy",
        "outputId": "3a031f3d-cbdd-44b0-bd91-21ab243e34aa"
      },
      "source": [
        "import os\n",
        "import numpy as np\n",
        "\n",
        "dataset = 'ViolentFlow-opt'\n",
        "num_epochs  = 30\n",
        "num_workers = 16\n",
        "batch_size  = 8\n",
        "\n",
        "val_generator = DataGenerator(directory='/content/drive/MyDrive/4_19data/example_npy'.format(dataset),\n",
        "                              batch_size=batch_size, \n",
        "                              data_augmentation=False)"
      ],
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 10 files belonging to 2 classes.\n",
            "     Fight :  0\n",
            "  NonFight :  1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O_bKLbl8PhGw"
      },
      "source": [
        "predict=model.predict(val_generator)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "329wGa6RWURi",
        "outputId": "bf7b8b60-465b-4ff1-ecd7-5622cdbfe140"
      },
      "source": [
        "predict"
      ],
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.16162232, 0.83837765],\n",
              "       [0.11178969, 0.8882103 ],\n",
              "       [0.9833272 , 0.01667285],\n",
              "       [0.845239  , 0.154761  ],\n",
              "       [0.6172777 , 0.38272232],\n",
              "       [0.8497123 , 0.15028764],\n",
              "       [0.9448912 , 0.05510884],\n",
              "       [0.15407637, 0.84592366],\n",
              "       [0.9404022 , 0.05959772],\n",
              "       [0.14582032, 0.8541797 ]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 96
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D5kNet84e-hH",
        "outputId": "6610aba6-98ed-416e-ce65-5c9009019f30"
      },
      "source": [
        "model.predict_generator(val_generator)"
      ],
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py:1905: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
            "  warnings.warn('`Model.predict_generator` is deprecated and '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.9404022 , 0.05959772],\n",
              "       [0.9833272 , 0.01667285],\n",
              "       [0.15407637, 0.8459236 ],\n",
              "       [0.11178969, 0.8882103 ],\n",
              "       [0.14582032, 0.8541797 ],\n",
              "       [0.845239  , 0.154761  ],\n",
              "       [0.9448912 , 0.05510884],\n",
              "       [0.8497123 , 0.15028769],\n",
              "       [0.16162232, 0.83837765],\n",
              "       [0.6172777 , 0.38272232]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 90
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YXmvzyUket3Z",
        "outputId": "af5a6aea-9c77-44cb-f2a7-40cca5e7db48"
      },
      "source": [
        "dir(model)"
      ],
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['_TF_MODULE_IGNORED_PROPERTIES',\n",
              " '__call__',\n",
              " '__class__',\n",
              " '__delattr__',\n",
              " '__dict__',\n",
              " '__dir__',\n",
              " '__doc__',\n",
              " '__eq__',\n",
              " '__format__',\n",
              " '__ge__',\n",
              " '__getattribute__',\n",
              " '__getstate__',\n",
              " '__gt__',\n",
              " '__hash__',\n",
              " '__init__',\n",
              " '__init_subclass__',\n",
              " '__le__',\n",
              " '__lt__',\n",
              " '__module__',\n",
              " '__ne__',\n",
              " '__new__',\n",
              " '__reduce__',\n",
              " '__reduce_ex__',\n",
              " '__repr__',\n",
              " '__setattr__',\n",
              " '__setstate__',\n",
              " '__sizeof__',\n",
              " '__str__',\n",
              " '__subclasshook__',\n",
              " '__weakref__',\n",
              " '_activity_regularizer',\n",
              " '_add_trackable',\n",
              " '_add_variable_with_custom_getter',\n",
              " '_assert_compile_was_called',\n",
              " '_assert_weights_created',\n",
              " '_auto_track_sub_layers',\n",
              " '_autocast',\n",
              " '_autographed_call',\n",
              " '_base_model_initialized',\n",
              " '_build_input_shape',\n",
              " '_call_accepts_kwargs',\n",
              " '_call_arg_was_passed',\n",
              " '_call_fn_arg_defaults',\n",
              " '_call_fn_arg_positions',\n",
              " '_call_fn_args',\n",
              " '_call_full_argspec',\n",
              " '_callable_losses',\n",
              " '_cast_single_input',\n",
              " '_check_call_args',\n",
              " '_checkpoint_dependencies',\n",
              " '_clear_losses',\n",
              " '_compile_was_called',\n",
              " '_compiled_trainable_state',\n",
              " '_compute_dtype',\n",
              " '_compute_dtype_object',\n",
              " '_compute_output_and_mask_jointly',\n",
              " '_compute_tensor_usage_count',\n",
              " '_configure_steps_per_execution',\n",
              " '_conform_to_reference_input',\n",
              " '_dedup_weights',\n",
              " '_default_training_arg',\n",
              " '_deferred_dependencies',\n",
              " '_distribution_strategy',\n",
              " '_dtype',\n",
              " '_dtype_policy',\n",
              " '_dynamic',\n",
              " '_eager_losses',\n",
              " '_enable_dict_to_input_mapping',\n",
              " '_expects_mask_arg',\n",
              " '_expects_training_arg',\n",
              " '_feed_input_names',\n",
              " '_feed_input_shapes',\n",
              " '_feed_inputs',\n",
              " '_flatten',\n",
              " '_flatten_layers',\n",
              " '_flatten_to_reference_inputs',\n",
              " '_functional_construction_call',\n",
              " '_gather_children_attribute',\n",
              " '_gather_saveables_for_checkpoint',\n",
              " '_get_call_arg_value',\n",
              " '_get_callback_model',\n",
              " '_get_compile_args',\n",
              " '_get_distribution_strategy',\n",
              " '_get_existing_metric',\n",
              " '_get_input_masks',\n",
              " '_get_node_attribute_at_index',\n",
              " '_get_optimizer',\n",
              " '_get_save_spec',\n",
              " '_get_trainable_state',\n",
              " '_graph_network_add_loss',\n",
              " '_graph_network_add_metric',\n",
              " '_handle_activity_regularization',\n",
              " '_handle_deferred_dependencies',\n",
              " '_handle_deferred_layer_dependencies',\n",
              " '_handle_weight_regularization',\n",
              " '_in_multi_worker_mode',\n",
              " '_inbound_nodes',\n",
              " '_inbound_nodes_value',\n",
              " '_infer_output_signature',\n",
              " '_init_batch_counters',\n",
              " '_init_call_fn_args',\n",
              " '_init_graph_network',\n",
              " '_init_set_name',\n",
              " '_initial_weights',\n",
              " '_input_coordinates',\n",
              " '_input_layers',\n",
              " '_input_spec',\n",
              " '_insert_layers',\n",
              " '_instrument_layer_creation',\n",
              " '_instrumented_keras_api',\n",
              " '_instrumented_keras_layer_class',\n",
              " '_instrumented_keras_model_class',\n",
              " '_is_compiled',\n",
              " '_is_graph_network',\n",
              " '_is_layer',\n",
              " '_is_model_for_instrumentation',\n",
              " '_keras_api_names',\n",
              " '_keras_api_names_v1',\n",
              " '_keras_tensor_symbolic_call',\n",
              " '_layer_call_argspecs',\n",
              " '_layer_checkpoint_dependencies',\n",
              " '_layers',\n",
              " '_list_extra_dependencies_for_serialization',\n",
              " '_list_functions_for_serialization',\n",
              " '_lookup_dependency',\n",
              " '_losses',\n",
              " '_map_resources',\n",
              " '_maybe_build',\n",
              " '_maybe_cast_inputs',\n",
              " '_maybe_create_attribute',\n",
              " '_maybe_initialize_trackable',\n",
              " '_maybe_load_initial_epoch_from_ckpt',\n",
              " '_metrics',\n",
              " '_metrics_lock',\n",
              " '_must_restore_from_config',\n",
              " '_name',\n",
              " '_name_based_attribute_restore',\n",
              " '_name_based_restores',\n",
              " '_name_scope',\n",
              " '_nested_inputs',\n",
              " '_nested_outputs',\n",
              " '_network_nodes',\n",
              " '_no_dependency',\n",
              " '_nodes_by_depth',\n",
              " '_non_trainable_weights',\n",
              " '_obj_reference_counts',\n",
              " '_obj_reference_counts_dict',\n",
              " '_object_identifier',\n",
              " '_outbound_nodes',\n",
              " '_outbound_nodes_value',\n",
              " '_output_coordinates',\n",
              " '_output_layers',\n",
              " '_output_mask_cache',\n",
              " '_output_shape_cache',\n",
              " '_output_tensor_cache',\n",
              " '_predict_counter',\n",
              " '_preload_simple_restoration',\n",
              " '_preserve_input_structure_in_config',\n",
              " '_reset_compile_cache',\n",
              " '_restore_from_checkpoint_position',\n",
              " '_run_eagerly',\n",
              " '_run_internal_graph',\n",
              " '_saved_model_inputs_spec',\n",
              " '_self_name_based_restores',\n",
              " '_self_saveable_object_factories',\n",
              " '_self_setattr_tracking',\n",
              " '_self_unconditional_checkpoint_dependencies',\n",
              " '_self_unconditional_deferred_dependencies',\n",
              " '_self_unconditional_dependency_names',\n",
              " '_self_update_uid',\n",
              " '_set_call_arg_value',\n",
              " '_set_connectivity_metadata',\n",
              " '_set_dtype_policy',\n",
              " '_set_inputs',\n",
              " '_set_mask_keras_history_checked',\n",
              " '_set_mask_metadata',\n",
              " '_set_output_names',\n",
              " '_set_save_spec',\n",
              " '_set_trainable_state',\n",
              " '_set_training_mode',\n",
              " '_setattr_tracking',\n",
              " '_should_cast_single_input',\n",
              " '_should_compute_mask',\n",
              " '_should_eval',\n",
              " '_single_restoration_from_checkpoint_position',\n",
              " '_split_out_first_arg',\n",
              " '_stateful',\n",
              " '_steps_per_execution',\n",
              " '_supports_masking',\n",
              " '_symbolic_call',\n",
              " '_tensor_usage_count',\n",
              " '_test_counter',\n",
              " '_tf_api_names',\n",
              " '_tf_api_names_v1',\n",
              " '_thread_local',\n",
              " '_track_trackable',\n",
              " '_trackable_saved_model_saver',\n",
              " '_trackable_saver',\n",
              " '_tracking_metadata',\n",
              " '_train_counter',\n",
              " '_trainable',\n",
              " '_trainable_weights',\n",
              " '_training_state',\n",
              " '_unconditional_checkpoint_dependencies',\n",
              " '_unconditional_dependency_names',\n",
              " '_undeduplicated_weights',\n",
              " '_update_uid',\n",
              " '_updated_config',\n",
              " '_updates',\n",
              " '_validate_compile',\n",
              " '_validate_graph_inputs_and_outputs',\n",
              " 'activity_regularizer',\n",
              " 'add_loss',\n",
              " 'add_metric',\n",
              " 'add_update',\n",
              " 'add_variable',\n",
              " 'add_weight',\n",
              " 'apply',\n",
              " 'build',\n",
              " 'built',\n",
              " 'call',\n",
              " 'compile',\n",
              " 'compiled_loss',\n",
              " 'compiled_metrics',\n",
              " 'compute_dtype',\n",
              " 'compute_mask',\n",
              " 'compute_output_shape',\n",
              " 'compute_output_signature',\n",
              " 'count_params',\n",
              " 'distribute_strategy',\n",
              " 'dtype',\n",
              " 'dtype_policy',\n",
              " 'dynamic',\n",
              " 'evaluate',\n",
              " 'evaluate_generator',\n",
              " 'fit',\n",
              " 'fit_generator',\n",
              " 'from_config',\n",
              " 'get_config',\n",
              " 'get_input_at',\n",
              " 'get_input_mask_at',\n",
              " 'get_input_shape_at',\n",
              " 'get_layer',\n",
              " 'get_losses_for',\n",
              " 'get_output_at',\n",
              " 'get_output_mask_at',\n",
              " 'get_output_shape_at',\n",
              " 'get_updates_for',\n",
              " 'get_weights',\n",
              " 'history',\n",
              " 'inbound_nodes',\n",
              " 'input',\n",
              " 'input_mask',\n",
              " 'input_names',\n",
              " 'input_shape',\n",
              " 'input_spec',\n",
              " 'inputs',\n",
              " 'layers',\n",
              " 'load_weights',\n",
              " 'loss',\n",
              " 'losses',\n",
              " 'make_predict_function',\n",
              " 'make_test_function',\n",
              " 'make_train_function',\n",
              " 'metrics',\n",
              " 'metrics_names',\n",
              " 'name',\n",
              " 'name_scope',\n",
              " 'non_trainable_variables',\n",
              " 'non_trainable_weights',\n",
              " 'optimizer',\n",
              " 'outbound_nodes',\n",
              " 'output',\n",
              " 'output_mask',\n",
              " 'output_names',\n",
              " 'output_shape',\n",
              " 'outputs',\n",
              " 'predict',\n",
              " 'predict_function',\n",
              " 'predict_generator',\n",
              " 'predict_on_batch',\n",
              " 'predict_step',\n",
              " 'reset_metrics',\n",
              " 'reset_states',\n",
              " 'run_eagerly',\n",
              " 'save',\n",
              " 'save_weights',\n",
              " 'set_weights',\n",
              " 'state_updates',\n",
              " 'stateful',\n",
              " 'stop_training',\n",
              " 'submodules',\n",
              " 'summary',\n",
              " 'supports_masking',\n",
              " 'test_function',\n",
              " 'test_on_batch',\n",
              " 'test_step',\n",
              " 'to_json',\n",
              " 'to_yaml',\n",
              " 'train_function',\n",
              " 'train_on_batch',\n",
              " 'train_step',\n",
              " 'trainable',\n",
              " 'trainable_variables',\n",
              " 'trainable_weights',\n",
              " 'updates',\n",
              " 'variable_dtype',\n",
              " 'variables',\n",
              " 'weights',\n",
              " 'with_name_scope']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 88
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RLtvhfL1bTME",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "04d62f7f-452c-4b3a-d6fa-4fa010b06533"
      },
      "source": [
        "len(predict)"
      ],
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "glQFGByMbTJW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cd82c441-f2be-4692-dec4-743a3870cc39"
      },
      "source": [
        "val_generator[0][1]\n"
      ],
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1., 0.],\n",
              "       [1., 0.]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 67
        }
      ]
    }
  ]
}